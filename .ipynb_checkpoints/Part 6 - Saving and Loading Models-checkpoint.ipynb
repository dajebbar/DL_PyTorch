{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading Models\n",
    "\n",
    "Save and load models with PyTorch. This is important because, often we want to load previously trained models to use in making predictions or to continue training on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import helper\n",
    "import fc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('FMNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('FMNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f12a37218b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 266,
       "width": 269
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "plt.imshow(image[0].numpy().squeeze(), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a network\n",
    "To make things more concise here, I moved the model architecture and training code from the last part to a file called `fc_model`. Importing this, we can easily create a fully-connected network with `fc_model.Network`, and train the network using `fc_model.train`. I'll use this model (once it's trained) to demonstrate how we can save and load models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the network, define the criterion and optimizer\n",
    "model = fc_model.Network(784, 10, [512, 256, 128])\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2..  Training Loss: 1.663..  Test Loss: 0.950..  Test Accuracy: 0.654\n",
      "Epoch: 1/2..  Training Loss: 1.039..  Test Loss: 0.733..  Test Accuracy: 0.729\n",
      "Epoch: 1/2..  Training Loss: 0.866..  Test Loss: 0.656..  Test Accuracy: 0.754\n",
      "Epoch: 1/2..  Training Loss: 0.771..  Test Loss: 0.654..  Test Accuracy: 0.744\n",
      "Epoch: 1/2..  Training Loss: 0.737..  Test Loss: 0.616..  Test Accuracy: 0.763\n",
      "Epoch: 1/2..  Training Loss: 0.739..  Test Loss: 0.592..  Test Accuracy: 0.775\n",
      "Epoch: 1/2..  Training Loss: 0.694..  Test Loss: 0.581..  Test Accuracy: 0.777\n",
      "Epoch: 1/2..  Training Loss: 0.649..  Test Loss: 0.546..  Test Accuracy: 0.796\n",
      "Epoch: 1/2..  Training Loss: 0.664..  Test Loss: 0.550..  Test Accuracy: 0.795\n",
      "Epoch: 1/2..  Training Loss: 0.690..  Test Loss: 0.529..  Test Accuracy: 0.805\n",
      "Epoch: 1/2..  Training Loss: 0.631..  Test Loss: 0.523..  Test Accuracy: 0.800\n",
      "Epoch: 1/2..  Training Loss: 0.604..  Test Loss: 0.514..  Test Accuracy: 0.811\n",
      "Epoch: 1/2..  Training Loss: 0.586..  Test Loss: 0.538..  Test Accuracy: 0.799\n",
      "Epoch: 1/2..  Training Loss: 0.612..  Test Loss: 0.497..  Test Accuracy: 0.815\n",
      "Epoch: 1/2..  Training Loss: 0.564..  Test Loss: 0.501..  Test Accuracy: 0.812\n",
      "Epoch: 1/2..  Training Loss: 0.578..  Test Loss: 0.509..  Test Accuracy: 0.818\n",
      "Epoch: 1/2..  Training Loss: 0.570..  Test Loss: 0.501..  Test Accuracy: 0.814\n",
      "Epoch: 1/2..  Training Loss: 0.581..  Test Loss: 0.528..  Test Accuracy: 0.797\n",
      "Epoch: 1/2..  Training Loss: 0.643..  Test Loss: 0.499..  Test Accuracy: 0.813\n",
      "Epoch: 1/2..  Training Loss: 0.587..  Test Loss: 0.492..  Test Accuracy: 0.820\n",
      "Epoch: 1/2..  Training Loss: 0.553..  Test Loss: 0.475..  Test Accuracy: 0.823\n",
      "Epoch: 1/2..  Training Loss: 0.614..  Test Loss: 0.522..  Test Accuracy: 0.807\n",
      "Epoch: 1/2..  Training Loss: 0.580..  Test Loss: 0.496..  Test Accuracy: 0.820\n",
      "Epoch: 2/2..  Training Loss: 0.573..  Test Loss: 0.491..  Test Accuracy: 0.821\n",
      "Epoch: 2/2..  Training Loss: 0.516..  Test Loss: 0.492..  Test Accuracy: 0.818\n",
      "Epoch: 2/2..  Training Loss: 0.540..  Test Loss: 0.460..  Test Accuracy: 0.833\n",
      "Epoch: 2/2..  Training Loss: 0.549..  Test Loss: 0.461..  Test Accuracy: 0.829\n",
      "Epoch: 2/2..  Training Loss: 0.506..  Test Loss: 0.468..  Test Accuracy: 0.828\n",
      "Epoch: 2/2..  Training Loss: 0.583..  Test Loss: 0.479..  Test Accuracy: 0.827\n",
      "Epoch: 2/2..  Training Loss: 0.525..  Test Loss: 0.466..  Test Accuracy: 0.831\n",
      "Epoch: 2/2..  Training Loss: 0.536..  Test Loss: 0.476..  Test Accuracy: 0.827\n",
      "Epoch: 2/2..  Training Loss: 0.501..  Test Loss: 0.473..  Test Accuracy: 0.825\n",
      "Epoch: 2/2..  Training Loss: 0.566..  Test Loss: 0.476..  Test Accuracy: 0.828\n",
      "Epoch: 2/2..  Training Loss: 0.533..  Test Loss: 0.449..  Test Accuracy: 0.837\n",
      "Epoch: 2/2..  Training Loss: 0.545..  Test Loss: 0.457..  Test Accuracy: 0.832\n",
      "Epoch: 2/2..  Training Loss: 0.494..  Test Loss: 0.444..  Test Accuracy: 0.836\n",
      "Epoch: 2/2..  Training Loss: 0.519..  Test Loss: 0.464..  Test Accuracy: 0.830\n",
      "Epoch: 2/2..  Training Loss: 0.513..  Test Loss: 0.442..  Test Accuracy: 0.835\n",
      "Epoch: 2/2..  Training Loss: 0.514..  Test Loss: 0.455..  Test Accuracy: 0.831\n",
      "Epoch: 2/2..  Training Loss: 0.539..  Test Loss: 0.437..  Test Accuracy: 0.840\n",
      "Epoch: 2/2..  Training Loss: 0.508..  Test Loss: 0.446..  Test Accuracy: 0.834\n",
      "Epoch: 2/2..  Training Loss: 0.526..  Test Loss: 0.453..  Test Accuracy: 0.835\n",
      "Epoch: 2/2..  Training Loss: 0.515..  Test Loss: 0.453..  Test Accuracy: 0.836\n",
      "Epoch: 2/2..  Training Loss: 0.521..  Test Loss: 0.461..  Test Accuracy: 0.832\n",
      "Epoch: 2/2..  Training Loss: 0.545..  Test Loss: 0.458..  Test Accuracy: 0.835\n",
      "Epoch: 2/2..  Training Loss: 0.506..  Test Loss: 0.439..  Test Accuracy: 0.839\n"
     ]
    }
   ],
   "source": [
    "fc_model.train(model, trainloader, testloader, criterion, optimizer, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and loading networks\n",
    "As you can imagine, it's impractical to train a network every time you need to use it. Instead, we can save trained networks then load them later to train more or use them for predictions.\n",
    "\n",
    "The parameters for `PyTorch` networks are stored in a model's `state_dict`. We can see the `state_dict` contains the weight and bias matrices for each of our layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "******************************************************************************************************************************************************\n",
      "odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print('**' * 75)\n",
    "print(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest thing to do is simply save the `state dict` with `torch.save`. For example, we can save it to a file 'checkpoint.pth'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can load the state dict with `torch.load`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('checkpoint.pth')\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to load the state dict in to the network, you do `model.load_state_dict(state_dict)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems pretty straightforward, but as usual it's a bit more complicated. Loading the state dict works only if the model architecture is exactly the same as the checkpoint architecture. If I create a model with a different architecture, this fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Network:\n\tsize mismatch for hidden_layers.0.weight: copying a param with shape torch.Size([512, 784]) from checkpoint, the shape in current model is torch.Size([400, 784]).\n\tsize mismatch for hidden_layers.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([400]).\n\tsize mismatch for hidden_layers.1.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([200, 400]).\n\tsize mismatch for hidden_layers.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([200]).\n\tsize mismatch for hidden_layers.2.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([100, 200]).\n\tsize mismatch for hidden_layers.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([100]).\n\tsize mismatch for output.weight: copying a param with shape torch.Size([10, 128]) from checkpoint, the shape in current model is torch.Size([10, 100]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-71971fc4ff68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# This will throw an error because the tensor sizes are wrong!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1052\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1053\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Network:\n\tsize mismatch for hidden_layers.0.weight: copying a param with shape torch.Size([512, 784]) from checkpoint, the shape in current model is torch.Size([400, 784]).\n\tsize mismatch for hidden_layers.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([400]).\n\tsize mismatch for hidden_layers.1.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([200, 400]).\n\tsize mismatch for hidden_layers.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([200]).\n\tsize mismatch for hidden_layers.2.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([100, 200]).\n\tsize mismatch for hidden_layers.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([100]).\n\tsize mismatch for output.weight: copying a param with shape torch.Size([10, 128]) from checkpoint, the shape in current model is torch.Size([10, 100])."
     ]
    }
   ],
   "source": [
    "model = fc_model.Network(784, 10, [400, 200, 100])\n",
    "\n",
    "# This will throw an error because the tensor sizes are wrong!\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
