{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import helper\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First up, we need to get our dataset. This is provided through the `torchvision` package. The code below will download the MNIST dataset, then create training and test datasets for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                             ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the training data loaded into `trainloader` and we make that an iterator with `iter(trainloader)`. We'd use this to loop through the dataset for training, but here I'm just grabbing the first batch so we can check out the data. We can see below that `images` is just a tensor with size (64, 1, 28, 28). So, 64 images per batch, 1 color channel, and 28x28 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f448faf5850>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 244,
       "width": 248
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0].numpy().squeeze(), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building networks with PyTorch\n",
    "\n",
    "Here I'll use PyTorch to build a simple feedfoward network to classify the MNIST images. That is, the network will receive a digit image as input and predict the digit in the image.\n",
    "\n",
    "<img src=\"assets/mlp_mnist.png\" width=600px>\n",
    "\n",
    "To build a neural network with PyTorch, you use the `torch.nn` module. The network itself is a class inheriting from `torch.nn.Module`. You define each of the operations separately, like `nn.Linear(784, 128)` for a fully connected linear layer with 784 inputs and 128 units.\n",
    "\n",
    "The class needs to include a `forward` method that implements the forward pass through the network. In this method, you pass some input tensor `x` through each of the operations you defined earlier. The `torch.nn` module also has functional equivalents for things like ReLUs in `torch.nn.functional`. This module is usually imported as `F`. Then to use a ReLU activation on some layer (which is just a tensor), you'd do `F.relu(x)`. Below are a few different commonly used activation functions.\n",
    "\n",
    "<img src=\"assets/activation.png\" width=700px>\n",
    "\n",
    "So, for this network, I'll build it with three fully connected layers, then a softmax output for predicting classes. The softmax function is similar to the sigmoid in that it squashes inputs between 0 and 1, but it's also normalized so that all the values sum to one like a proper probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MnistNetwork(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MnistNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Defining the fully connected layers (fc), 128, 64, 10 units each\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ''' Forward pass through the network, returns the output logits  '''\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = MnistNetwork()\n",
    "\n",
    "model\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing weights and biases\n",
    "\n",
    "The weights and such are automatically initialized for you, but it's possible to customize how they are initialized. The weights and biases are tensors attached to the layer you defined, you can get them with `model.fc1.weight` for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.0100,  0.0071, -0.0168,  ...,  0.0180,  0.0140,  0.0201],\n",
      "        [-0.0174,  0.0224,  0.0346,  ..., -0.0009,  0.0022,  0.0344],\n",
      "        [-0.0256,  0.0336,  0.0115,  ...,  0.0160, -0.0105, -0.0086],\n",
      "        ...,\n",
      "        [-0.0321,  0.0021,  0.0145,  ...,  0.0336, -0.0083, -0.0264],\n",
      "        [ 0.0223,  0.0316,  0.0241,  ..., -0.0134,  0.0319,  0.0267],\n",
      "        [ 0.0295, -0.0118, -0.0063,  ..., -0.0004,  0.0159, -0.0005]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 3.5260e-02, -1.5285e-02, -1.1703e-02,  1.5549e-02,  2.2927e-02,\n",
      "        -2.3352e-02,  3.5303e-02, -1.3779e-02,  2.9326e-03, -2.1896e-02,\n",
      "        -2.1665e-03,  2.7818e-02, -5.1452e-03, -1.0615e-02, -3.2885e-02,\n",
      "        -2.7995e-02, -1.2419e-02,  8.0221e-03, -1.5402e-02,  1.4722e-02,\n",
      "        -3.4755e-02, -2.5055e-02, -1.0293e-02,  6.0369e-03, -1.6685e-02,\n",
      "        -2.8174e-02,  2.5951e-02,  2.9742e-02,  2.9749e-02, -2.4695e-02,\n",
      "         2.1802e-02,  1.8613e-02,  5.4327e-03, -2.9873e-02, -2.4238e-03,\n",
      "        -1.6044e-02, -4.5653e-04,  9.5873e-03, -1.8165e-03,  1.2661e-02,\n",
      "        -1.2572e-02,  1.5737e-02,  1.4336e-02,  6.6924e-03, -3.0212e-02,\n",
      "         3.3847e-03, -2.6093e-02, -1.6408e-03,  3.4509e-02, -3.5548e-02,\n",
      "        -1.7793e-02, -2.3051e-02,  3.4387e-02,  2.9731e-03, -1.9288e-02,\n",
      "        -3.2401e-02, -6.6730e-03,  3.6626e-03, -3.0510e-02,  6.4294e-03,\n",
      "         2.5826e-02,  7.2286e-03, -2.8218e-02, -1.9412e-02,  2.9510e-02,\n",
      "        -2.8575e-02,  3.0363e-02,  1.5141e-02,  2.8414e-02,  9.6411e-04,\n",
      "        -1.5427e-02, -3.3466e-02, -1.3579e-02,  5.9666e-03,  2.7288e-02,\n",
      "         1.9128e-02,  1.2887e-02, -2.8312e-02,  2.9303e-02, -4.7734e-03,\n",
      "        -1.4618e-02, -1.2854e-02, -4.9689e-05,  2.1605e-03, -7.5330e-03,\n",
      "        -9.1868e-03,  9.7710e-03, -4.7871e-03,  8.7766e-03,  2.8509e-02,\n",
      "        -1.1034e-02, -1.8942e-02, -3.5302e-02,  3.3238e-02, -1.5875e-02,\n",
      "        -1.5281e-02,  3.4168e-02,  2.0598e-02,  7.5773e-03, -1.9493e-02,\n",
      "         2.6362e-02,  2.3567e-02,  8.5493e-03, -3.0746e-02,  1.9733e-02,\n",
      "        -1.7362e-02,  5.6352e-03,  2.6404e-02, -2.3498e-02, -2.4419e-02,\n",
      "         3.3632e-02,  2.6974e-03,  2.7800e-02,  1.6015e-02,  1.1453e-02,\n",
      "         3.4240e-02,  3.0068e-02, -3.9313e-03,  3.0506e-02, -7.1456e-04,\n",
      "        -3.1868e-02, -3.0249e-02,  1.1737e-02, -6.7045e-03,  1.1297e-02,\n",
      "        -1.1794e-02, -1.5384e-02, -1.0132e-02], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0650, -0.0223, -0.0850,  ..., -0.0320,  0.0116, -0.0535],\n",
      "        [ 0.0819,  0.0078,  0.0335,  ...,  0.0290, -0.0766, -0.0298],\n",
      "        [ 0.0037,  0.0526, -0.0627,  ...,  0.0629,  0.0194, -0.0787],\n",
      "        ...,\n",
      "        [-0.0597,  0.0106,  0.0566,  ...,  0.0490,  0.0670,  0.0295],\n",
      "        [ 0.0420,  0.0308, -0.0116,  ..., -0.0861,  0.0184,  0.0214],\n",
      "        [ 0.0837, -0.0292,  0.0022,  ..., -0.0453,  0.0442,  0.0579]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0093,  0.0102, -0.0811,  0.0835,  0.0547, -0.0289, -0.0303,  0.0402,\n",
      "         0.0441,  0.0119, -0.0849, -0.0655,  0.0477,  0.0649, -0.0552,  0.0564,\n",
      "         0.0055, -0.0320,  0.0341, -0.0862,  0.0584, -0.0482,  0.0609,  0.0883,\n",
      "        -0.0878, -0.0173,  0.0741, -0.0188, -0.0316,  0.0427, -0.0271,  0.0816,\n",
      "        -0.0479,  0.0207, -0.0299, -0.0199,  0.0743, -0.0027, -0.0653,  0.0759,\n",
      "         0.0878, -0.0562, -0.0230,  0.0881,  0.0746, -0.0033,  0.0292,  0.0699,\n",
      "        -0.0299, -0.0750,  0.0725, -0.0504,  0.0221,  0.0874,  0.0171, -0.0165,\n",
      "        -0.0192,  0.0133,  0.0739, -0.0508, -0.0872,  0.0730,  0.0397, -0.0843],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-8.1317e-02,  1.5462e-02, -9.6122e-02,  4.3017e-02, -2.9795e-02,\n",
      "         -4.4725e-03,  1.1973e-01, -2.1836e-02,  4.9638e-02, -2.6045e-02,\n",
      "          3.5294e-02, -1.0978e-01,  7.4400e-02,  6.3621e-02,  1.0692e-01,\n",
      "          7.1583e-02, -8.3440e-02, -5.0680e-02,  1.0061e-02,  1.2426e-01,\n",
      "         -7.7721e-02,  5.4634e-02, -6.8110e-02,  2.5522e-02,  8.6599e-02,\n",
      "         -1.2284e-01, -6.6095e-02, -8.5289e-02, -8.7154e-02,  1.1787e-02,\n",
      "         -1.6634e-02, -1.2099e-01, -8.2544e-02, -1.0340e-01,  1.1908e-01,\n",
      "          4.5409e-02, -2.6683e-02,  7.0823e-02,  6.6443e-02, -3.4577e-02,\n",
      "         -6.1558e-02,  4.5857e-02, -4.7400e-02,  3.7840e-02, -6.2165e-02,\n",
      "         -1.1866e-01, -1.0701e-01,  9.3183e-02, -8.9330e-02, -6.7346e-02,\n",
      "          7.0892e-02,  6.9283e-02, -8.1483e-02,  3.4359e-02,  1.2407e-01,\n",
      "         -7.7802e-02,  9.8568e-02,  6.3832e-02,  5.7228e-02, -1.9289e-02,\n",
      "          2.5840e-02,  1.4792e-02, -6.0601e-02,  3.5565e-02],\n",
      "        [-2.5349e-02,  5.9414e-02,  2.6666e-02,  3.4120e-02, -5.8350e-02,\n",
      "          5.1829e-02,  1.3342e-02, -6.9274e-02, -5.6088e-03, -9.7548e-02,\n",
      "          6.9991e-02, -5.2409e-02, -9.2834e-02, -1.2566e-02,  7.1777e-02,\n",
      "          8.2310e-02,  1.1145e-02, -9.6906e-02,  7.7370e-02,  8.6218e-02,\n",
      "         -6.3918e-02,  4.3725e-03,  7.4469e-02,  3.9786e-04,  5.7313e-02,\n",
      "         -8.1790e-03,  9.7450e-02,  1.2220e-01,  1.0599e-02, -4.3946e-02,\n",
      "          2.5006e-02,  8.1379e-02,  2.8964e-03, -4.2217e-02,  7.8791e-02,\n",
      "         -3.3277e-03,  2.7214e-02,  2.0536e-02,  9.1844e-02, -9.2134e-02,\n",
      "          6.4209e-02,  3.7207e-02,  9.2595e-02,  7.2195e-02, -4.6546e-02,\n",
      "         -9.4893e-02, -5.2610e-02,  1.2009e-01,  5.8793e-02, -5.2841e-03,\n",
      "         -1.0486e-01, -1.2351e-01, -1.0188e-01, -9.5659e-04, -7.1281e-02,\n",
      "         -9.8504e-02,  6.6993e-02,  7.8248e-02, -8.5345e-02,  5.7095e-02,\n",
      "         -7.4640e-02,  7.4433e-02,  1.8358e-03, -3.5561e-02],\n",
      "        [-6.9178e-02, -4.1261e-03,  9.6890e-02,  1.1125e-01,  1.2339e-01,\n",
      "          9.2372e-02, -3.7565e-02,  5.0231e-02, -1.2496e-01,  9.3597e-02,\n",
      "          4.1810e-02,  4.7855e-02, -6.4275e-02, -4.9928e-02,  7.4905e-02,\n",
      "         -1.1200e-01, -1.0883e-01,  1.1902e-01,  9.8297e-02, -2.1602e-02,\n",
      "          6.3728e-02, -6.0628e-02, -8.2954e-02,  7.8146e-02, -1.0243e-01,\n",
      "         -6.0060e-02, -9.4530e-02,  4.7437e-03,  6.8823e-02,  4.3598e-02,\n",
      "          3.9067e-02, -8.0901e-02, -1.2476e-01,  5.0147e-02, -3.4385e-02,\n",
      "          2.6195e-03,  1.0909e-01, -1.2165e-01,  1.1859e-01,  6.2588e-02,\n",
      "          7.2256e-02,  1.0693e-01,  4.9058e-03, -1.1896e-01,  5.6180e-02,\n",
      "         -1.4799e-02,  2.9361e-02, -2.6088e-02,  1.1074e-01,  1.0693e-01,\n",
      "         -3.8431e-02,  1.1362e-01,  5.9726e-02, -3.5145e-02, -4.2696e-02,\n",
      "          7.7209e-02,  1.1482e-01,  1.9461e-02,  6.2668e-02, -4.2738e-02,\n",
      "         -1.2299e-01,  5.8835e-02,  5.0548e-02,  7.9899e-02],\n",
      "        [ 1.9767e-02, -1.4809e-02, -1.1287e-01,  2.4976e-03, -3.8787e-02,\n",
      "          9.1298e-02, -6.7054e-02,  8.4565e-02,  9.8598e-02,  5.8229e-02,\n",
      "         -8.3597e-02, -4.5036e-02,  1.0997e-02, -1.0719e-01, -1.2393e-01,\n",
      "         -1.1460e-01, -7.6414e-02, -6.5195e-03,  9.2812e-02, -6.8682e-02,\n",
      "         -9.0304e-02, -3.9147e-02, -1.4182e-02,  4.1028e-02,  6.0011e-02,\n",
      "          4.3560e-02,  1.0706e-01, -8.1565e-02,  3.6769e-03,  1.0567e-01,\n",
      "         -1.5440e-02, -9.4153e-02, -9.7290e-02,  9.8391e-02, -1.1247e-01,\n",
      "          2.4256e-02, -6.8156e-02, -7.1040e-02,  5.3725e-04,  1.1769e-01,\n",
      "          7.8962e-02, -2.5128e-02,  7.2839e-02,  4.8602e-02,  1.2460e-01,\n",
      "         -9.0020e-02, -6.9805e-02, -2.8912e-02, -2.5621e-02,  7.4537e-02,\n",
      "         -8.7195e-02, -9.1250e-02,  9.3894e-02,  2.5730e-02, -3.4604e-02,\n",
      "          4.4151e-02, -8.5132e-03,  6.8211e-02, -1.1936e-01, -1.2106e-01,\n",
      "          1.0381e-01,  1.1411e-01,  2.3445e-02, -8.6716e-02],\n",
      "        [ 2.2515e-02,  3.6463e-02,  1.1917e-01,  8.0860e-02,  4.7723e-02,\n",
      "         -1.2096e-01,  2.8395e-02, -3.0256e-02,  5.8160e-02,  5.3898e-02,\n",
      "         -6.5008e-02,  6.0041e-02,  9.4503e-02, -5.7349e-02, -8.1407e-02,\n",
      "          1.2313e-01,  9.4562e-02, -7.9486e-02, -4.3397e-02, -7.4252e-05,\n",
      "         -6.7583e-02,  8.4147e-02, -3.5924e-02, -4.5231e-02, -1.9736e-02,\n",
      "         -4.8850e-03, -3.7177e-02, -2.4178e-02,  5.4989e-02, -1.2197e-01,\n",
      "         -4.0579e-02, -4.9797e-02, -4.1025e-02,  1.1353e-01,  6.8974e-02,\n",
      "          4.4111e-02, -8.2296e-03, -1.1987e-01,  7.4278e-02, -6.4940e-02,\n",
      "          3.9670e-02,  2.3352e-02,  2.0402e-02,  8.7141e-02, -1.9341e-02,\n",
      "         -9.8859e-02,  9.8120e-02, -6.8559e-03,  7.9902e-02,  4.5862e-02,\n",
      "         -7.4276e-02,  8.2959e-02,  5.2007e-02,  4.4337e-02, -1.0857e-01,\n",
      "          1.1640e-01, -1.6337e-02,  1.8683e-02,  8.5156e-03,  7.8320e-02,\n",
      "         -4.9938e-02,  6.6604e-02, -9.6269e-02, -8.3784e-02],\n",
      "        [ 6.8593e-02,  1.9931e-02,  5.4964e-02,  1.1377e-01, -1.1584e-01,\n",
      "         -6.3156e-02, -1.0618e-01,  6.6872e-03,  6.3532e-02,  2.8217e-02,\n",
      "         -1.1850e-03, -1.0350e-01,  1.2111e-01, -6.5073e-02,  1.2370e-01,\n",
      "         -1.5749e-02, -5.3071e-02,  5.2206e-02, -4.2424e-02,  1.1986e-01,\n",
      "          7.7083e-02, -7.5531e-02, -6.4896e-03, -1.2126e-01,  5.8558e-02,\n",
      "          4.5424e-02,  5.5131e-02, -8.1215e-02, -1.1362e-01, -3.8085e-03,\n",
      "          5.1343e-02, -1.1705e-01,  1.1921e-01, -6.7460e-02, -3.7357e-02,\n",
      "          1.0600e-01,  6.2979e-02,  1.2413e-01,  9.1128e-02,  2.2231e-02,\n",
      "          1.0699e-01,  1.3752e-02,  9.7766e-02,  8.2879e-02,  1.0388e-01,\n",
      "          2.7927e-02,  2.8600e-02,  9.4718e-02, -8.6124e-02,  1.2339e-01,\n",
      "         -9.1695e-02, -8.6780e-02,  2.8164e-02,  4.7463e-03,  7.2481e-03,\n",
      "         -6.2888e-02,  8.5154e-02,  9.7878e-02,  1.2218e-01, -7.3317e-02,\n",
      "         -1.1263e-01, -8.6509e-02,  7.3828e-02, -5.4623e-02],\n",
      "        [-3.9683e-02, -6.4479e-02, -7.5540e-02, -7.5605e-02,  2.6258e-02,\n",
      "         -5.8752e-02,  1.0750e-01, -1.9649e-02, -4.5631e-02, -6.9456e-02,\n",
      "          1.1937e-01, -2.1466e-02,  1.1954e-01,  7.2331e-02,  1.1598e-01,\n",
      "          5.3640e-02, -3.7193e-02, -8.6925e-02,  2.7423e-02, -8.2797e-02,\n",
      "          2.9392e-03, -2.2379e-02,  2.0923e-02, -1.2113e-01,  1.7345e-02,\n",
      "         -8.1538e-02, -4.6571e-02,  9.3348e-03,  1.1174e-01,  3.2762e-02,\n",
      "          9.4350e-02, -1.1529e-02, -6.7505e-02, -4.5628e-02, -1.0486e-01,\n",
      "         -8.7593e-02,  1.8967e-02, -7.3726e-02, -4.6633e-02,  1.1033e-02,\n",
      "          1.1908e-01, -4.6017e-02,  7.4689e-02,  1.0369e-01, -1.1243e-01,\n",
      "          7.2567e-02, -2.7690e-02, -1.5827e-02, -1.0138e-01,  7.3505e-02,\n",
      "         -7.7797e-02, -6.6856e-02, -9.9964e-02,  9.5152e-02,  9.2855e-02,\n",
      "         -1.1585e-01, -1.1966e-01, -5.7442e-02, -3.0403e-02, -3.4563e-02,\n",
      "         -1.1931e-01,  1.0180e-01, -6.8919e-02, -8.2386e-02],\n",
      "        [-9.2666e-02,  4.2633e-02, -9.3543e-02, -1.1941e-01, -1.1663e-01,\n",
      "          1.0737e-01, -4.7178e-02,  8.1099e-02, -3.5029e-02,  7.2469e-02,\n",
      "         -1.1911e-01,  7.2518e-02, -1.0986e-01, -9.6398e-02,  2.8989e-02,\n",
      "          1.1862e-01,  1.1704e-01, -3.1591e-02, -3.8323e-03, -7.7164e-02,\n",
      "         -3.1473e-02, -1.0783e-01, -1.0960e-01, -8.1745e-02, -5.7098e-02,\n",
      "         -2.6864e-02,  2.6801e-02, -8.6541e-02, -8.6278e-02, -4.0209e-02,\n",
      "         -7.6244e-03, -2.0990e-02,  2.5900e-02, -8.1743e-02, -7.1844e-02,\n",
      "          3.2902e-02,  3.1972e-02,  5.7358e-02,  8.8181e-02, -8.3377e-02,\n",
      "          1.2008e-01, -7.3895e-02,  1.0377e-01,  8.7423e-03, -4.9631e-02,\n",
      "          7.4243e-02, -7.0361e-02, -6.3992e-02, -8.9035e-02, -4.6479e-02,\n",
      "         -4.4695e-03, -9.7817e-02, -6.3508e-02, -1.2379e-01, -7.4831e-02,\n",
      "          1.4846e-02,  5.7852e-02,  1.2002e-02, -2.7558e-02, -1.1143e-01,\n",
      "         -1.0657e-01, -6.5477e-02, -1.2074e-01,  4.9462e-02],\n",
      "        [ 9.7870e-02, -6.9947e-02,  5.3296e-02,  9.4398e-02, -1.0022e-01,\n",
      "         -5.8727e-02,  5.1833e-02, -1.0768e-01,  1.1219e-01, -5.1683e-02,\n",
      "          1.0982e-02,  1.0177e-01, -1.0439e-01, -1.9464e-02, -1.1226e-01,\n",
      "          4.1683e-02,  4.0208e-02, -6.2833e-02,  6.7955e-02,  9.0863e-02,\n",
      "         -5.1865e-02, -8.8474e-02, -1.3655e-02,  1.2135e-01,  3.2930e-02,\n",
      "         -1.2374e-01,  6.1216e-02,  4.1465e-02,  1.2173e-01, -2.5257e-02,\n",
      "          6.4015e-02, -1.2018e-01, -1.1845e-01, -8.7557e-02, -1.2294e-01,\n",
      "         -8.7310e-02,  7.7029e-02, -1.2243e-01, -1.1760e-01, -1.4946e-02,\n",
      "          1.1787e-01, -2.6334e-02, -6.6919e-02, -7.3404e-03,  9.9461e-02,\n",
      "         -9.0072e-02, -1.7296e-02,  1.4127e-02, -8.0309e-02, -3.5355e-03,\n",
      "          6.1610e-04, -1.8838e-02, -8.6675e-02,  1.0434e-01,  9.3264e-03,\n",
      "         -9.5863e-02, -4.5996e-02, -7.1504e-02, -2.2290e-02,  5.0251e-02,\n",
      "          6.4946e-02,  1.2189e-01,  1.2243e-01, -9.1818e-02],\n",
      "        [ 3.0229e-02, -4.1532e-02,  5.3584e-02, -6.7877e-02, -4.7244e-02,\n",
      "         -1.1843e-02,  4.0173e-02, -5.6983e-02,  1.1883e-01,  5.4811e-02,\n",
      "         -5.9888e-02,  8.7062e-02, -9.8631e-05, -5.3297e-03,  8.5757e-03,\n",
      "         -7.3628e-02, -5.7037e-02,  7.8583e-02, -1.2016e-01, -1.0535e-03,\n",
      "         -3.8864e-03, -6.8586e-02,  8.5147e-02, -5.6570e-03,  7.8395e-02,\n",
      "         -2.9050e-02,  3.7117e-02, -8.6063e-02,  1.1017e-02,  7.7268e-02,\n",
      "         -1.0048e-02,  6.4152e-02,  4.6092e-02,  2.6197e-02,  9.9223e-02,\n",
      "          8.6447e-03,  5.8768e-02, -1.5291e-03,  8.6072e-02, -3.7050e-02,\n",
      "         -4.2728e-02,  4.8513e-02, -4.0852e-03,  3.6997e-02, -3.2647e-02,\n",
      "         -1.1677e-02,  1.0014e-01, -9.1296e-02, -5.3395e-02, -1.0544e-01,\n",
      "         -6.7868e-02,  7.9611e-02,  1.0464e-02, -1.1390e-01,  4.9992e-02,\n",
      "          1.0749e-01, -1.0186e-01,  1.0939e-01, -4.6981e-02,  7.1713e-02,\n",
      "          4.6265e-02, -7.5767e-02, -9.5259e-02, -7.8081e-02]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.1218,  0.0881, -0.1026, -0.0380, -0.0258, -0.0147,  0.0899,  0.0047,\n",
      "        -0.0245,  0.0042], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0100,  0.0071, -0.0168,  ...,  0.0180,  0.0140,  0.0201],\n",
      "        [-0.0174,  0.0224,  0.0346,  ..., -0.0009,  0.0022,  0.0344],\n",
      "        [-0.0256,  0.0336,  0.0115,  ...,  0.0160, -0.0105, -0.0086],\n",
      "        ...,\n",
      "        [-0.0321,  0.0021,  0.0145,  ...,  0.0336, -0.0083, -0.0264],\n",
      "        [ 0.0223,  0.0316,  0.0241,  ..., -0.0134,  0.0319,  0.0267],\n",
      "        [ 0.0295, -0.0118, -0.0063,  ..., -0.0004,  0.0159, -0.0005]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 3.5260e-02, -1.5285e-02, -1.1703e-02,  1.5549e-02,  2.2927e-02,\n",
      "        -2.3352e-02,  3.5303e-02, -1.3779e-02,  2.9326e-03, -2.1896e-02,\n",
      "        -2.1665e-03,  2.7818e-02, -5.1452e-03, -1.0615e-02, -3.2885e-02,\n",
      "        -2.7995e-02, -1.2419e-02,  8.0221e-03, -1.5402e-02,  1.4722e-02,\n",
      "        -3.4755e-02, -2.5055e-02, -1.0293e-02,  6.0369e-03, -1.6685e-02,\n",
      "        -2.8174e-02,  2.5951e-02,  2.9742e-02,  2.9749e-02, -2.4695e-02,\n",
      "         2.1802e-02,  1.8613e-02,  5.4327e-03, -2.9873e-02, -2.4238e-03,\n",
      "        -1.6044e-02, -4.5653e-04,  9.5873e-03, -1.8165e-03,  1.2661e-02,\n",
      "        -1.2572e-02,  1.5737e-02,  1.4336e-02,  6.6924e-03, -3.0212e-02,\n",
      "         3.3847e-03, -2.6093e-02, -1.6408e-03,  3.4509e-02, -3.5548e-02,\n",
      "        -1.7793e-02, -2.3051e-02,  3.4387e-02,  2.9731e-03, -1.9288e-02,\n",
      "        -3.2401e-02, -6.6730e-03,  3.6626e-03, -3.0510e-02,  6.4294e-03,\n",
      "         2.5826e-02,  7.2286e-03, -2.8218e-02, -1.9412e-02,  2.9510e-02,\n",
      "        -2.8575e-02,  3.0363e-02,  1.5141e-02,  2.8414e-02,  9.6411e-04,\n",
      "        -1.5427e-02, -3.3466e-02, -1.3579e-02,  5.9666e-03,  2.7288e-02,\n",
      "         1.9128e-02,  1.2887e-02, -2.8312e-02,  2.9303e-02, -4.7734e-03,\n",
      "        -1.4618e-02, -1.2854e-02, -4.9689e-05,  2.1605e-03, -7.5330e-03,\n",
      "        -9.1868e-03,  9.7710e-03, -4.7871e-03,  8.7766e-03,  2.8509e-02,\n",
      "        -1.1034e-02, -1.8942e-02, -3.5302e-02,  3.3238e-02, -1.5875e-02,\n",
      "        -1.5281e-02,  3.4168e-02,  2.0598e-02,  7.5773e-03, -1.9493e-02,\n",
      "         2.6362e-02,  2.3567e-02,  8.5493e-03, -3.0746e-02,  1.9733e-02,\n",
      "        -1.7362e-02,  5.6352e-03,  2.6404e-02, -2.3498e-02, -2.4419e-02,\n",
      "         3.3632e-02,  2.6974e-03,  2.7800e-02,  1.6015e-02,  1.1453e-02,\n",
      "         3.4240e-02,  3.0068e-02, -3.9313e-03,  3.0506e-02, -7.1456e-04,\n",
      "        -3.1868e-02, -3.0249e-02,  1.1737e-02, -6.7045e-03,  1.1297e-02,\n",
      "        -1.1794e-02, -1.5384e-02, -1.0132e-02], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.fc1.weight)\n",
    "print(model.fc1.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For custom initialization, we want to modify these tensors in place. These are actually autograd *Variables*, so we need to get back the actual tensors with `model.fc1.weight.data`. Once we have the tensors, we can fill them with zeros (for biases) or random normal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set biases to all zeros\n",
    "# model.fc1.bias.data.fill_(0)\n",
    "\n",
    "# sample from random normal with standard dev = 0.01\n",
    "# model.fc1.weight.data.normal_(std=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass\n",
    "\n",
    "Now that we have a network, let's see what happens when we pass in an image. This is called the forward pass. We're going to convert the image data into a tensor, then pass it through the operations defined by the network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
